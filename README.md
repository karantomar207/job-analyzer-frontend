# JobLens AI â€“ Smart Job Page Analyzer
### "Know your chances before you apply."

A production-ready **Chrome Extension** powered by **Groq AI** that automatically analyzes job pages, matches them against your resume, detects hidden requirements, and gives you actionable insights â€” all in seconds.

---

## ðŸ“‚ Project Structure

```
job-analyzer/
â”œâ”€â”€ manifest.json           # Chrome MV3 manifest
â”œâ”€â”€ background.js           # Service worker: routing, caching, rate limiting
â”œâ”€â”€ content.js              # Job detection + Shadow DOM overlay panel
â”œâ”€â”€ popup.html              # Extension popup (4-tab UI)
â”œâ”€â”€ popup.js                # Popup logic
â”œâ”€â”€ popup.css               # Popup styles
â”œâ”€â”€ styles.css              # Page-level stylesheet (minimal)
â”œâ”€â”€ icons/                  # Extension icons (16/32/48/128px)
â””â”€â”€ utils/
    â”œâ”€â”€ jobExtractor.js     # LinkedIn/Internshala/generic DOM parser
    â”œâ”€â”€ resumeParser.js     # Client-side PDF/DOCX/text parser
    â””â”€â”€ apiClient.js        # Background worker comms + storage helpers

backend/
â”œâ”€â”€ main.py                 # FastAPI app entry point
â”œâ”€â”€ config.py               # Pydantic settings (reads .env)
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env.example            # Environment variable template
â”œâ”€â”€ routes/
â”‚   â””â”€â”€ analyze.py          # POST /analyze endpoint
â””â”€â”€ services/
    â””â”€â”€ groqService.py      # Groq LLM integration + prompt engineering
```

---

## ðŸš€ Quick Start

### 1. Backend Setup

```bash
cd backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env and add your GROQ_API_KEY from https://console.groq.com
nano .env

# Start the server
python main.py
# Server runs at http://localhost:8000
```

### 2. Load the Extension

1. Open Chrome â†’ `chrome://extensions/`
2. Enable **Developer Mode** (top right)
3. Click **"Load unpacked"**
4. Select the `job-analyzer/` folder (this folder)
5. The JobLens AI icon appears in your toolbar âœ…

### 3. First Use

1. Click the **JobLens AI** icon in your toolbar
2. Go to **Resume tab** â†’ Upload your PDF/DOCX or paste resume text â†’ **Save**
3. Navigate to a LinkedIn or Internshala job page
4. The floating **JobLens** button appears on the right side of the page
5. Click **"Analyze My Match"** in the popup or click the side panel button
6. Get your full AI analysis in ~5-10 seconds ðŸŽ‰

---

## ðŸ”‘ Getting a Groq API Key

1. Go to [console.groq.com](https://console.groq.com)
2. Sign up / Log in
3. Navigate to **API Keys** â†’ **Create API Key**
4. Copy the key and paste it in `backend/.env`

---

## ðŸ§  How It Works

```
Job Page (LinkedIn/Internshala)
    â†“ DOM Parsing (content.js)
    â†“ jobExtractor.js extracts: title, company, description, skills
    â†“
Popup / Overlay triggers analysis
    â†“ resume loaded from chrome.storage.local
    â†“
background.js (service worker)
    â†“ checks rate limit (10/day)
    â†“ checks URL cache (24h TTL)
    â†“
POST /analyze â†’ FastAPI Backend
    â†“ groqService.py builds rich prompt
    â†“ Groq LLM (llama-3.3-70b-versatile)
    â†“ JSON response parsed + validated
    â†“
Result â†’ cached â†’ sent back to extension
    â†“
Overlay panel shows:
  â€¢ Match % (circular progress)
  â€¢ Matched / Missing skills
  â€¢ Hidden requirements
  â€¢ ATS keywords gap
  â€¢ Resume improvement tips
  â€¢ Recommended projects
```

---

## ðŸ“Š Features

| Feature | Status |
|---------|--------|
| LinkedIn job extraction | âœ… |
| Internshala job extraction | âœ… |
| Generic career page extraction | âœ… |
| PDF resume parsing (client-side) | âœ… |
| DOCX resume parsing (client-side) | âœ… |
| Groq AI analysis | âœ… |
| Match percentage + circle UI | âœ… |
| Hidden requirements detection | âœ… |
| ATS keyword gap analysis | âœ… |
| Resume improvement suggestions | âœ… |
| Project recommendations | âœ… |
| URL-based result caching (24h) | âœ… |
| Rate limiting (10/day) | âœ… |
| Analysis history | âœ… |
| Shadow DOM overlay (no style leak) | âœ… |
| Resume stored locally only | âœ… |
| Backend API key proxy | âœ… |

---

## ðŸ”’ Security & Privacy

- **Resume never leaves your device** (stored in `chrome.storage.local`)
- **Groq API key stored server-side only** â€“ never exposed to browser
- Shadow DOM overlay prevents CSS conflicts with host page
- Rate limiting prevents abuse (10 analyses/day)
- No analytics or tracking

---

## ðŸ›  Development

### Backend API Docs
After starting the server, visit: `http://localhost:8000/docs`

### Changing the AI Model
Edit `backend/services/groqService.py`:
```python
model: str = "llama-3.3-70b-versatile"  # change to any Groq model
```

Available Groq models: `llama-3.1-8b-instant` (faster), `llama-3.3-70b-versatile` (recommended), `mixtral-8x7b-32768`

---

## ðŸš§ Future Roadmap

- [ ] Apply with AI-optimized resume
- [ ] Generate custom cover letter
- [ ] Track applied jobs dashboard
- [ ] Job alerts / saved searches
- [ ] Subscription system
- [ ] Deploy backend to Railway/Render

---

## ðŸ“„ License
MIT
